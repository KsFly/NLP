{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#合併AA-AM中檔案成13個檔\n",
    "for i in range(65,78):   \n",
    "    #獲取目標資料夾的路徑 \n",
    "    meragefiledir = os.getcwd()+'\\\\wiki_zh\\\\A'+chr(i)\n",
    "    #獲取當前資料夾中的檔名稱列表 \n",
    "    filenames=os.listdir(meragefiledir) \n",
    "    \n",
    "    file=open('./combine/A'+chr(i)+'.txt','w',encoding='utf-8') \n",
    "    #向檔案中寫入字元 \n",
    "\n",
    "    #先遍歷檔名 \n",
    "    for filename in filenames: \n",
    "      filepath=meragefiledir+'\\\\'\n",
    "      filepath=filepath+filename\n",
    "      #遍歷單個檔案，讀取行數 \n",
    "      for line in open(filepath,'r',encoding='utf-8'): \n",
    "        file.writelines(line) \n",
    "        file.write('\\n') \n",
    "    #關閉檔案 \n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將上面13個檔案再合併成wiki.txt\n",
    "\n",
    "meragefiledir = os.getcwd()+'\\\\combine'\n",
    "\n",
    "filenames=os.listdir(meragefiledir) \n",
    "\n",
    "file=open('wiki.txt','w',encoding='utf-8') \n",
    "#向檔案中寫入字元 \n",
    " \n",
    "#先遍歷檔名 \n",
    "for filename in filenames: \n",
    "  filepath=meragefiledir+'\\\\'\n",
    "  filepath=filepath+filename\n",
    "  #遍歷單個檔案，讀取行數 \n",
    "  for line in open(filepath,'r',encoding='utf-8'): \n",
    "    file.writelines(line) \n",
    "  file.write('\\n') \n",
    "#關閉檔案 \n",
    "file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import codecs\n",
    " \n",
    "#整理檔案成result.txt\n",
    "def filte(input_file):\n",
    "    p1 = re.compile('[（\\(][，；。？！\\s]*[）\\)]')\n",
    "    p2 = re.compile('《》')\n",
    "    p3 = re.compile('「')\n",
    "    p4 = re.compile('」')\n",
    "    p5 = re.compile('{\"id\":')\n",
    "    p6 = re.compile('\"}')\n",
    "    p7 = re.compile('『』')\n",
    "    p8 = re.compile('『')\n",
    "    p9 = re.compile('』')\n",
    "    p10 = re.compile('-\\{.*?(zh-hans|zh-cn):([^;]*?)(;.*?)?\\}-')\n",
    "    p11=re.compile('\"url\": \"https://zh.wikipedia.org/wiki?curid=')\n",
    "    \n",
    "    #input_file1=input_file[10:]\n",
    "    #input_file1='./test/'+input_file1.replace('/','')\n",
    "    outfile = codecs.open('result.txt', 'w', 'utf-8')\n",
    "    with codecs.open(input_file, 'r', 'utf-8') as myfile:\n",
    "        for line in myfile:\n",
    "            line=line.replace(r'\\n','')\n",
    "            line=line.replace('\"url\": \"https://zh.wikipedia.org/wiki?curid=','')\n",
    "            line=line.replace('\"title\":','')\n",
    "            line=line.replace('\"text\": \"','')\n",
    "            line = p1.sub('', line)\n",
    "            line = p2.sub('', line)\n",
    "            line = p3.sub('“', line)\n",
    "            line = p4.sub('”', line)\n",
    "            line = p5.sub('', line)\n",
    "            line = p6.sub('', line)\n",
    "            line = p7.sub('', line)\n",
    "            line = p8.sub('“', line)\n",
    "            line = p9.sub('”', line)\n",
    "            line = p10.sub('', line)\n",
    "            outfile.write(line)\n",
    "    outfile.close()\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    input_file = 'wiki.txt'\n",
    "    filte(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from opencc import OpenCC\n",
    "\n",
    "#處理檔案\n",
    "cc = OpenCC('s2t')\n",
    "\n",
    "with open('result2.txt', 'w', encoding='utf-8') as new_f:\n",
    "    with open('result.txt', 'r', encoding='utf-8') as f:\n",
    "        for times, data in enumerate(f, 1):\n",
    "            #print('data num:', times)\n",
    "            data = cc.convert(data)\n",
    "            data = jieba.cut(data)\n",
    "            data = [word for word in data if word != ' ']\n",
    "            data = ' '.join(data)\n",
    "\n",
    "            new_f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "# Settings\n",
    "seed = 666\n",
    "sg = 0\n",
    "window_size = 10\n",
    "vector_size = 100\n",
    "min_count = 1\n",
    "workers = 8\n",
    "epochs = 5\n",
    "batch_words = 10000\n",
    "\n",
    "train_data = word2vec.LineSentence('result2.txt')\n",
    "model = word2vec.Word2Vec(train_data)\n",
    "\n",
    "model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('申世景', 0.8342980742454529)\n",
      "('曹培昌', 0.8284943699836731)\n",
      "('柯錦華', 0.8272031545639038)\n",
      "('吳辰君', 0.8210703730583191)\n",
      "('蔡明修', 0.8179910182952881)\n",
      "('洪劍濤', 0.8177291750907898)\n",
      "('崔嬉序', 0.8174335956573486)\n",
      "('汪明欣', 0.8174027800559998)\n",
      "('金度延', 0.8170691132545471)\n",
      "('吳祺', 0.8162655234336853)\n",
      "('王日升', 0.8160404562950134)\n",
      "('富永美', 0.8151085376739502)\n",
      "('廖海鷹', 0.8144931197166443)\n",
      "('金成鈴', 0.8139917850494385)\n",
      "('譚永浩', 0.8135719299316406)\n",
      "('李伊庚', 0.8132534623146057)\n",
      "('周源', 0.8122381567955017)\n",
      "('李燕萍', 0.8117225766181946)\n",
      "('孫公紱', 0.8108137249946594)\n",
      "('江語晨', 0.8104578852653503)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec.load('word2vec.model')\n",
    "#print(model.wv['李知恩'].shape)\n",
    "\n",
    "for item in model.wv.most_similar('李知恩',topn=20):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
