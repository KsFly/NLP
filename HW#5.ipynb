{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file = open('translation2019zh_train.json' , 'r',encoding='utf-8') \n",
    "\n",
    "en_data=[]\n",
    "ch_data=[]\n",
    "\n",
    "for line in file.readlines():\n",
    "    tmp=json.loads(line)\n",
    "    en_data.append(tmp['english'])\n",
    "    ch_data.append(tmp['chinese'])\n",
    "\n",
    "#print(en[5161433])\n",
    "#print(ch[5161433])\n",
    "#print(en[:10])\n",
    "#print(ch[:10])\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分別生成中英文字典\n",
    "en_vocab = set(''.join(en_data))\n",
    "id2en = list(en_vocab)\n",
    "en2id = {c:i for i,c in enumerate(id2en)}\n",
    "\n",
    "# 分別生成中英文字典\n",
    "ch_vocab = set(''.join(ch_data))\n",
    "id2ch = list(ch_vocab)\n",
    "ch2id = {c:i for i,c in enumerate(id2ch)}\n",
    "\n",
    "#print(en2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char: I didn't own a Thesaurus until four years ago and I use a small Webster's dictionary that I'd bought at K-Mart for 89 cents.\n",
      "index: [98, 38, 154, 25, 154, 108, 104, 152, 38, 110, 59, 108, 38, 2, 38, 36, 48, 57, 39, 2, 139, 144, 139, 39, 38, 139, 108, 152, 25, 76, 38, 37, 110, 139, 144, 38, 5, 57, 2, 144, 39, 38, 2, 24, 110, 38, 2, 108, 154, 38, 98, 38, 139, 39, 57, 38, 2, 38, 39, 43, 2, 76, 76, 38, 83, 57, 75, 39, 152, 57, 144, 104, 39, 38, 154, 25, 14, 152, 25, 110, 108, 2, 144, 5, 38, 152, 48, 2, 152, 38, 98, 104, 154, 38, 75, 110, 139, 24, 48, 152, 38, 2, 152, 38, 40, 116, 10, 2, 144, 152, 38, 37, 110, 144, 38, 85, 7, 38, 14, 57, 108, 152, 39, 78]\n"
     ]
    }
   ],
   "source": [
    "en_num_data = [[en2id[en] for en in line ] for line in en_data]\n",
    "ch_num_data = [[ch2id[ch] for ch in line] for line in ch_data]\n",
    "de_num_data = [[ch2id[ch] for ch in line][1:] for line in ch_data]\n",
    "\n",
    "print('char:', en_data[1])\n",
    "print('index:', en_num_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max encoder length: 256\n",
      "max decoder length: 174\n",
      "index data:\n",
      " [98, 38, 154, 25, 154, 108, 104, 152, 38, 110, 59, 108, 38, 2, 38, 36, 48, 57, 39, 2, 139, 144, 139, 39, 38, 139, 108, 152, 25, 76, 38, 37, 110, 139, 144, 38, 5, 57, 2, 144, 39, 38, 2, 24, 110, 38, 2, 108, 154, 38, 98, 38, 139, 39, 57, 38, 2, 38, 39, 43, 2, 76, 76, 38, 83, 57, 75, 39, 152, 57, 144, 104, 39, 38, 154, 25, 14, 152, 25, 110, 108, 2, 144, 5, 38, 152, 48, 2, 152, 38, 98, 104, 154, 38, 75, 110, 139, 24, 48, 152, 38, 2, 152, 38, 40, 116, 10, 2, 144, 152, 38, 37, 110, 144, 38, 85, 7, 38, 14, 57, 108, 152, 39, 78]\n",
      "one hot data:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 獲取輸入輸出端的最大長度\n",
    "max_encoder_seq_length = max([len(txt) for txt in en_num_data])\n",
    "max_decoder_seq_length = max([len(txt) for txt in ch_num_data])\n",
    "print('max encoder length:', max_encoder_seq_length)\n",
    "print('max decoder length:', max_decoder_seq_length)\n",
    "\n",
    "# 將數據進行onehot處理\n",
    "encoder_input_data = np.zeros((len(en_num_data), max_encoder_seq_length, len(en2id)), dtype='float16')\n",
    "decoder_input_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float16')\n",
    "decoder_target_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float16')\n",
    "\n",
    "for i in range(len(ch_num_data)):\n",
    "    for t, j in enumerate(en_num_data[i]):\n",
    "        encoder_input_data[i, t, j] = 1.\n",
    "    for t, j in enumerate(ch_num_data[i]):\n",
    "        decoder_input_data[i, t, j] = 1.\n",
    "    for t, j in enumerate(de_num_data[i]):\n",
    "        decoder_target_data[i, t, j] = 1.\n",
    "\n",
    "print('index data:\\n', en_num_data[1])\n",
    "print('one hot data:\\n', encoder_input_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_VOCAB_SIZE = len(en2id)\n",
    "CH_VOCAB_SIZE = len(ch2id)\n",
    "HIDDEN_SIZE = 256\n",
    "\n",
    "LEARNING_RATE = 0.003\n",
    "BATCH_SIZE = 200\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "# ==============encoder=============\n",
    "encoder_inputs = Input(shape=(None, EN_VOCAB_SIZE))\n",
    "#emb_inp = Embedding(output_dim=HIDDEN_SIZE, input_dim=EN_VOCAB_SIZE)(encoder_inputs)\n",
    "encoder_h1, encoder_state_h1, encoder_state_c1 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True)(encoder_inputs)\n",
    "encoder_h2, encoder_state_h2, encoder_state_c2 = LSTM(HIDDEN_SIZE, return_state=True)(encoder_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, CH_VOCAB_SIZE))\n",
    "\n",
    "#emb_target = Embedding(output_dim=HIDDEN_SIZE, input_dim=CH_VOCAB_SIZE, mask_zero=True)(decoder_inputs)\n",
    "lstm1 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True)\n",
    "lstm2 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True)\n",
    "decoder_dense = Dense(CH_VOCAB_SIZE, activation='softmax')\n",
    "\n",
    "decoder_h1, _, _ = lstm1(decoder_inputs, initial_state=[encoder_state_h1, encoder_state_c1])\n",
    "decoder_h2, _, _ = lstm2(decoder_h1, initial_state=[encoder_state_h2, encoder_state_c2])\n",
    "decoder_outputs = decoder_dense(decoder_h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 159)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None, 2919)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  425984      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   [(None, None, 256),  3252224     input_3[0][0]                    \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, 256), (None, 525312      lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   [(None, None, 256),  525312      lstm_5[0][0]                     \n",
      "                                                                 lstm_4[0][1]                     \n",
      "                                                                 lstm_4[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2919)   750183      lstm_6[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,479,015\n",
      "Trainable params: 5,479,015\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/50\n",
      "2000/2000 [==============================] - 290s 145ms/step - loss: 1.4526 - accuracy: 0.0360\n",
      "Epoch 2/50\n",
      "2000/2000 [==============================] - 308s 154ms/step - loss: 1.3439 - accuracy: 0.0067\n",
      "Epoch 3/50\n",
      "2000/2000 [==============================] - 250s 125ms/step - loss: 1.3319 - accuracy: 0.0080\n",
      "Epoch 4/50\n",
      "2000/2000 [==============================] - 241s 121ms/step - loss: 1.3250 - accuracy: 0.0080\n",
      "Epoch 5/50\n",
      "2000/2000 [==============================] - 240s 120ms/step - loss: 1.3210 - accuracy: 0.0087\n",
      "Epoch 6/50\n",
      "2000/2000 [==============================] - 243s 122ms/step - loss: 1.3185 - accuracy: 0.0089\n",
      "Epoch 7/50\n",
      "2000/2000 [==============================] - 248s 124ms/step - loss: 1.3167 - accuracy: 0.0091\n",
      "Epoch 8/50\n",
      "2000/2000 [==============================] - 245s 123ms/step - loss: 1.3237 - accuracy: 0.0089\n",
      "Epoch 9/50\n",
      "2000/2000 [==============================] - 247s 123ms/step - loss: 1.3192 - accuracy: 0.0092\n",
      "Epoch 10/50\n",
      "2000/2000 [==============================] - 249s 125ms/step - loss: 1.3116 - accuracy: 0.0093\n",
      "Epoch 11/50\n",
      "2000/2000 [==============================] - 263s 132ms/step - loss: 1.3099 - accuracy: 0.0094\n",
      "Epoch 12/50\n",
      "2000/2000 [==============================] - 318s 159ms/step - loss: 1.3118 - accuracy: 0.0093\n",
      "Epoch 13/50\n",
      "2000/2000 [==============================] - 326s 163ms/step - loss: 1.3119 - accuracy: 0.0090\n",
      "Epoch 14/50\n",
      "2000/2000 [==============================] - 323s 162ms/step - loss: 1.3069 - accuracy: 0.0090\n",
      "Epoch 15/50\n",
      "2000/2000 [==============================] - 322s 161ms/step - loss: 1.3007 - accuracy: 0.0091\n",
      "Epoch 16/50\n",
      "2000/2000 [==============================] - 321s 161ms/step - loss: 1.2953 - accuracy: 0.0091\n",
      "Epoch 17/50\n",
      "2000/2000 [==============================] - 322s 161ms/step - loss: 1.2895 - accuracy: 0.0091\n",
      "Epoch 18/50\n",
      "2000/2000 [==============================] - 327s 164ms/step - loss: 1.2867 - accuracy: 0.0093\n",
      "Epoch 19/50\n",
      "2000/2000 [==============================] - 326s 163ms/step - loss: 1.2808 - accuracy: 0.0093\n",
      "Epoch 20/50\n",
      "2000/2000 [==============================] - 332s 166ms/step - loss: 1.2764 - accuracy: 0.0093\n",
      "Epoch 21/50\n",
      "2000/2000 [==============================] - 326s 163ms/step - loss: 1.2711 - accuracy: 0.0094\n",
      "Epoch 22/50\n",
      "2000/2000 [==============================] - 326s 163ms/step - loss: 1.2635 - accuracy: 0.0096\n",
      "Epoch 23/50\n",
      "2000/2000 [==============================] - 325s 163ms/step - loss: 1.2572 - accuracy: 0.0100\n",
      "Epoch 24/50\n",
      "2000/2000 [==============================] - 331s 165ms/step - loss: 1.2432 - accuracy: 0.0103\n",
      "Epoch 25/50\n",
      "2000/2000 [==============================] - 326s 163ms/step - loss: 1.2316 - accuracy: 0.0106\n",
      "Epoch 26/50\n",
      "2000/2000 [==============================] - 343s 171ms/step - loss: 1.2253 - accuracy: 0.0111\n",
      "Epoch 27/50\n",
      "2000/2000 [==============================] - 337s 168ms/step - loss: 1.2160 - accuracy: 0.0117\n",
      "Epoch 28/50\n",
      "2000/2000 [==============================] - 338s 169ms/step - loss: 1.2089 - accuracy: 0.0121\n",
      "Epoch 29/50\n",
      "2000/2000 [==============================] - 332s 166ms/step - loss: 1.2021 - accuracy: 0.0125\n",
      "Epoch 30/50\n",
      "2000/2000 [==============================] - 332s 166ms/step - loss: 1.1938 - accuracy: 0.0130\n",
      "Epoch 31/50\n",
      "2000/2000 [==============================] - 337s 169ms/step - loss: 1.1878 - accuracy: 0.0135\n",
      "Epoch 32/50\n",
      "2000/2000 [==============================] - 339s 169ms/step - loss: 1.1753 - accuracy: 0.0142\n",
      "Epoch 33/50\n",
      "2000/2000 [==============================] - 331s 165ms/step - loss: 1.1659 - accuracy: 0.0147\n",
      "Epoch 34/50\n",
      "2000/2000 [==============================] - 338s 169ms/step - loss: 1.1562 - accuracy: 0.0150\n",
      "Epoch 35/50\n",
      "2000/2000 [==============================] - 332s 166ms/step - loss: 1.1459 - accuracy: 0.0159\n",
      "Epoch 36/50\n",
      "2000/2000 [==============================] - 331s 166ms/step - loss: 1.1363 - accuracy: 0.0170\n",
      "Epoch 37/50\n",
      "2000/2000 [==============================] - 335s 168ms/step - loss: 1.1276 - accuracy: 0.0174\n",
      "Epoch 38/50\n",
      "2000/2000 [==============================] - 360s 180ms/step - loss: 1.1175 - accuracy: 0.0182\n",
      "Epoch 39/50\n",
      "2000/2000 [==============================] - 338s 169ms/step - loss: 1.1066 - accuracy: 0.0186\n",
      "Epoch 40/50\n",
      "2000/2000 [==============================] - 334s 167ms/step - loss: 1.0967 - accuracy: 0.0195\n",
      "Epoch 41/50\n",
      "2000/2000 [==============================] - 348s 174ms/step - loss: 1.0874 - accuracy: 0.0201\n",
      "Epoch 42/50\n",
      "2000/2000 [==============================] - 342s 171ms/step - loss: 1.0809 - accuracy: 0.0205\n",
      "Epoch 43/50\n",
      "2000/2000 [==============================] - 337s 169ms/step - loss: 1.0674 - accuracy: 0.0218\n",
      "Epoch 44/50\n",
      "2000/2000 [==============================] - 339s 170ms/step - loss: 1.0555 - accuracy: 0.0225\n",
      "Epoch 45/50\n",
      "2000/2000 [==============================] - 343s 171ms/step - loss: 1.0445 - accuracy: 0.0232\n",
      "Epoch 46/50\n",
      "2000/2000 [==============================] - 343s 172ms/step - loss: 1.0354 - accuracy: 0.0241\n",
      "Epoch 47/50\n",
      "2000/2000 [==============================] - 339s 170ms/step - loss: 1.0256 - accuracy: 0.0248\n",
      "Epoch 48/50\n",
      "2000/2000 [==============================] - 341s 170ms/step - loss: 1.0171 - accuracy: 0.0254\n",
      "Epoch 49/50\n",
      "2000/2000 [==============================] - 358s 179ms/step - loss: 1.0092 - accuracy: 0.0263\n",
      "Epoch 50/50\n",
      "2000/2000 [==============================] - 350s 175ms/step - loss: 0.9990 - accuracy: 0.0270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x21828f9eb48>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "opt = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=BATCH_SIZE,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, [encoder_state_h1, encoder_state_c1, encoder_state_h2, encoder_state_c2])\n",
    "\n",
    "# 預測模型中的decoder的初始化狀態需要傳入新的狀態\n",
    "decoder_state_input_h1 = Input(shape=(HIDDEN_SIZE,))\n",
    "decoder_state_input_c1 = Input(shape=(HIDDEN_SIZE,))\n",
    "decoder_state_input_h2 = Input(shape=(HIDDEN_SIZE,))\n",
    "decoder_state_input_c2 = Input(shape=(HIDDEN_SIZE,))\n",
    "\n",
    "# 使用傳入的值來初始化當前模型的輸入狀態\n",
    "decoder_h1, state_h1, state_c1 = lstm1(decoder_inputs, initial_state=[decoder_state_input_h1, decoder_state_input_c1])\n",
    "decoder_h2, state_h2, state_c2 = lstm2(decoder_h1, initial_state=[decoder_state_input_h2, decoder_state_input_c2])\n",
    "decoder_outputs = decoder_dense(decoder_h2)\n",
    "\n",
    "decoder_model = Model([decoder_inputs, decoder_state_input_h1, decoder_state_input_c1, decoder_state_input_h2, decoder_state_input_c2], \n",
    "                      [decoder_outputs, state_h1, state_c1, state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slowly and not without struggle, America began to listen.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "I didn't own a Thesaurus until four years ago and I use a small Webster's dictionary that I'd bought at K-Mart for 89 cents.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "portlet, you must write three short deployment descriptors: web.xml, portlet.xml, and geronimo-web.xml. (Some of these may have been generated by your IDE.)\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Dithering is a technique that blends your colors together, making them look smoother, or just creating interesting textures.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "This paper discusses the petrologic characteristics of the coal-bearing strata under the geologic structural background of the Tertiary coal basin in Hunchun.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Women over 55 are pickier about their partners than at any other time in their lives.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Ruben: So, to heal (with capital letters) you need to have no predilections.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The second encounter relates to my grandfather's treasure box.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Change the value for the <ejb-link> tag to MyEJB, which is the name of the EJB as defined in the ejb-jar.xml file.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "One way to address these challenges would be to establish a Truth and Reconciliation Commission modeled on the experience of Muggle South Africa.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Brain: If you don't mind, Jonathan, while you and Mr. Sun get acquainted, I'd like to check the arrangements for the meeting.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Bailee Madison plays Sally, a young girl who goes to live with her father and his girlfriend.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Reduce blood fat, prevent thrombosis, arteriosclerosis, apoplexy and heart disease. Improve memory, nourish the brain and improve the intelligence.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Toomay said signs of community intolerance, including bumper stickers opposing same-sex marriage, also made him feel down, and he sought guidance from a school counselor after contemplating suicide.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "When you eat dinner out, reduce the temptation to clean your plate by setting aside one-third of your meal.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Sang Lan is one of the best athletes in our country.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "They are able to show that active peroxiredoxin 1, Prx1, an enzyme that breaks down harmful hydrogen peroxide in the cells, is required for caloric restriction to work effectively.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "He went to slide upon the ice Before the ice would bear; Then he plunged in above his knees, Which made poor Simon stare.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Miaoxiang son know the devil tricks, white three quick deployment.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "“My daughter has been banned from watching the show, ” supermodel Cindy Crawford told ShowbizSpy.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "\"The Chinese Super League starts in a couple of weeks and Sheffield United have asked me to go over and have a look at the coaching set-up, \" said McKinna.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "On the fifteenth day of that month the Lord 's Feast of Unleavened Bread begins; for seven days you must eat bread made without yeast.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "This paper consists of 3 parts:the monitorial system, the pupil-teacher system, and the historic role of the monitorial system & the pupil-teacher system.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Further development of the central cell mainly involved changes in the orientation of the polar nuclei and the distribution of the cytoplasm.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The first parameter to the script is saved to a variable called $IP.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Effective microbicides mean women can act independently to protect themselves against HIV/AIDS.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "当我把消息告诉她时，她简直目瞪口呆。\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "KEY LARGO, Fla. - The newborn calf of a deaf bottlenose dolphin that was found stranded last fall off a Florida beach died Friday at a marine mammal rehabilitation center.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Despite some real scandals at Fannie and Freddie, they played little role in causing the crisis: most of the really bad lending came from private loan originators.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "His time of 13 seconds is his best result since his injury four years ago.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "They walked in a stooped posture, the shoulders well forward, the head still farther forward, the eyes bent upon the ground.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "In the East, Manichaeism survived until the 13th century.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "I am clearly warning against that, because what you get is liable to be mediocrity.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "He could see I meant what I said. So he took his fur coat and left.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "But the main problem hasn't been solved which emphasizes on the system of curriculum and the integrity of the teaching content.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Mr Blake:This is my son, Timmy.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Few people studying Gauge Field Theory need to be convinced of the importance of the work of 't Hooft.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Shanghai is a varicolored world.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Using this in concert with the exec() command and dumping the results to an array allows you to build an HTML table or form that then allows you to run other commands.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "As a result, the equivalent model of contactless smart card and the interrogator was accomplished, which was verified by the simulation of Hspice software.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Because, by all accounts, that would be fostering a climate of lying and dishonesty.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Therefore, laminoplasty with its ability to address multiple levels, and limited short- and long-term morbidity, despite neck pain, is the author's procedure of choice.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "It will actively foster volunteer teams.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Frank Miller's dispiriting take on The Spirit a couple of years ago could easily have laid the subgenre to rest for a generation.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "E. g. Dalian is one of the most beautiful cities in China.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Truth, good and beauty have always been considered as the three top pursuits of human beings.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Li Shizhen own invention, he is the main drug observe, study and practical application of the new discovery, new experiences, thus greatly enriched and improved the knowledge of herbal medicine.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Even though vitamin C-rich foods are probably the first thing you think of when you feel a cold coming, the illness-preventing power of the antioxidant is debatable.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Further perfecting and developing shareholding system economy is still disrupted by the problem, that shareholding system belongs to capitalism or socialism, in people's ideology.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "At last, the design method of widened pavement was proposed with considering tension strength as a controlling index.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Conclusion: MRA combined with MRI and enhanced multi-slice CT is an accurate modality in making the early diagnosis of vertebral artery type cervical spondylosis.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Jane: You've been out every night for the last three weeks. Don't you know what's been happening?\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "CallXML is a platform specific to Voxeo.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "So i did this, and now i have 75.6 gigs free.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Find out Staff's realty incenter requirement, to accelerate staff motivate by themselves, rein-force the inspirit function of human' s inherence factor.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The lower-right corner of the source rectangle is mapped to the implicit fourth point in the parallelogram.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The start of the season, everybody was just like, \"They're not going to be in there.\"\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "n 20th-century high schools, shop and home economics classes were considered easy As—or worse, one-way tickets to unexciting vocations.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The influence of fin al pyrolysis temperature(FPT)on the pyrolytic yield of biomass has been studied.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Ingredients : wheat flour, sugar, vegetable oil, corn starch, whey powder, milk powder, cheese powder, salt, leaving agent, food color.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Hye-na Kang, the only successor of Kang-san Group, is the owner of the 'Lady Castle' and lives a 'princess-like' life with her servants.\n",
      "于的的的的的的的的的的的的的的的的的的的的\n",
      "For example, up to 70% of women and a significant proportion of men with gonococcal and/or chlamydial infections may experience no symptoms at all.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over the years, Col Gaddafi had fallen out with both his neighbours and the West, although he had bankrolled many African leaders.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Hope that help is what causes, and the other want to recommend a 1.6 the following handwriting input method. thanks.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Why wait around hoping to be picked for the next season of The Bachelor when the land of virtual romance awaits?\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Department stores:Projected to lose 10.2 percent of the 1.56 million jobs they had in 2008.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The measured value of particle, sheet resistance and film thickness have been respectively recorded in a table, please see table2.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Last week a male student in Zhejiang streaked to protest his school's rule that all power be shut off by 11:30 pm.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "I am almost all white, although my fur may turn yellow in summer.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "He outperformed everyone on the test last week.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Xiao li said no, can finish it in notepad.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The fourth part analyze and explain for GMTC new products developed strategy, and analyze innovative method and process for special steel new products;\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "However, when sailing by the lee or directly downwind, her leeward side is the side on which her mainsail lies. The other side is her windward side.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Last year, the Chinese Eximbank pledged $20bn in development funds for African infrastructure and trade financing over the next three years, funds that outstripped all western donor pledges combined.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Finally, you can experiment with Scilab's graph library and link to a saved graph through XHTML.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Major gifts are at least US$10,000 and can be made either to the Annual Programs Fund, Permanent Fund, or a restricted TRF program.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The British Monarchy Website Flickr account streams both up-to-the-minute images of royal engagements and archive photographs from the royal collection.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "A large, gray building sat behind an energy wall. It was built of blocks of stone and looked like a prison.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "For Professor Howard Cantril of Princeton University and colleagues, this provided the perfect opportunity to investigate the anatomy of panic (Cantril, Gaudet & Herzog, 1940).\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "A slight narrowing of the eyes is an instinctual, universal expression of anger across various species in the animal kingdom (think about the angry expressions of tigers, dogs, etc.).\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The participants carried out the positive discussion on the possible economic and trade cooperation with Luxemburg, and were more confident about Lu as the fast track to Europe markets.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "There is some dispute regarding the association of sildenafil with arrhythmias, where the available evidence is not clear.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "And scientists are focusing on the pathways for dopamine and similar neurotransmitters active in the circuits that pass information to and from the frontal lobes.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "This strong degree of metallic yarn , and traction ability.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "“They are a part of life,” Nikitina writes.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The influence of the suspension parameters on the dynamic performance of the articulated container flat car is studied and the suspension parameters are optimized.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "In this article, the application of industrial textiles in biomedical field is concluded, especially artificial skin, artificial blood vessel, artificial kidney, artificial pancreas, artificial bone.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "You worry a lot and you’re always easily upset.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The scene is the crowning glory of this marvellously entertaining show.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Close all blind flanges, inspection holes and manholes.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "There are cruises on Friday and Saturday February 13th and 14th.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "For its special structure and working circumstance, so far it is the unique transporting means.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Then the media weighed in on Odom's regular-season effort with barely a shrug: Odom finished sixth in the voting for sixth man of the year after his numbers were slightly down in many categories.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Today, Marcus is a short, thickset redhead with a lot of energy, just like his father.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Once they're investigated, their stock prices and their bond prices are going to fall.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "But two years later, the Web-savvy coverage of Tuesday's election highlights the growing sophistication of interactive media, social media and mobile apps。\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Model principle: Excert the power of personality of a politics teacher.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "Despite doubts about the extent and novelty of these new resources, the fact remains that the IMF has more money available.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "DAT is the north channel for automobile shipping.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n",
      "The honor belongs to the Excellent teachers and directors of Young Pioneer of Guangzhou.\n",
      "文性物的的电化的电理机、特化、工度、工术、\n"
     ]
    }
   ],
   "source": [
    "for k in range(0,100):\n",
    "    test_data = encoder_input_data[k:k+1]\n",
    "    h1, c1, h2, c2 = encoder_model.predict(test_data)\n",
    "    target_seq = np.zeros((1, 1, CH_VOCAB_SIZE))\n",
    "    #target_seq[0, 0, ch2id['\\t']] = 1\n",
    "    outputs = []\n",
    "    while True:\n",
    "        output_tokens, h1, c1, h2, c2 = decoder_model.predict([target_seq, h1, c1, h2, c2])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        outputs.append(sampled_token_index)\n",
    "        target_seq = np.zeros((1, 1, CH_VOCAB_SIZE))\n",
    "        target_seq[0, 0, sampled_token_index] = 1\n",
    "        #if sampled_token_index == ch2id['\\n'] or len(outputs) > 20: break\n",
    "        if len(outputs) > 20: break\n",
    "    \n",
    "    print(en_data[k])\n",
    "    print(''.join([id2ch[i] for i in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
